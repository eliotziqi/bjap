# PRD：Blackjack Trainer

---

## 1. 产品定位

本产品是一个以 21 点 Blackjack 为载体的 **决策训练系统**。
其目的不是模拟赌场娱乐体验，也不是追求赢钱结果，而是通过系统化训练，帮助用户在明确规则前提下，持续做出**长期期望值最优的决策**。

系统将 Blackjack 拆解为一系列**可枚举、可重复、可评估的决策场景**，并通过不同层级的训练模式，逐步将“策略记忆”转化为“条件反射式的正确决策”。

---

## 2. 核心目标与约束

系统的核心目标包括：

* 用户在指定规则下，准确记忆并理解 Basic Strategy
* 用户能解释某一决策在统计层面为何优于其他选择
* 用户在无提示环境下仍能保持高决策正确率
* 用户在接近真实牌桌压力（连续操作、资金波动）的条件下，仍能坚持策略而非情绪决策

系统明确约束自身边界：

* 不模拟真实赢钱刺激
* 不承担职业化赌徒工具职责
* 不引入账号系统或长期行为追踪
* 不尝试解决“如何赢钱”这一问题

---

## 3. 总体学习与训练路径

系统提供一条推荐的训练路径，用于匹配用户从“认知理解”到“行为内化”的自然过程：

规则设置 → 策略记忆 → 场景理解 → 无提示练习 → 连续实战模拟 → 数据回顾

该路径决定了顶层导航的默认顺序与信息架构，但系统不强制用户按线性顺序完成。用户可以在任意阶段自由切换 Tab、回退或跳转，系统应保证不同入口进入同一功能时的体验一致。

路径中的每一环节对应不同训练强度与信息披露程度：

* 策略记忆强调“应该怎么做”
* 场景理解强调“为什么这么做”
* 无提示练习强调“是否能做对”
* 连续实战模拟强调“在真实节奏与压力下是否仍能做对”
* 数据回顾用于发现薄弱点并反向驱动下一轮训练

系统应支持用户在任意环节形成闭环：从数据回顾定位弱点 → 跳回策略或场景理解 → 再进入无提示练习或模拟巩固。该闭环是核心使用方式之一。

---

## 4. 规则设置系统（Rules Configuration）

规则设置系统用于定义当前训练环境中 Blackjack 的行为边界与策略前提。所有策略记忆、场景学习、练习判定与模拟结算均依赖规则，但系统不要求用户在每次切换功能前都手动管理规则；相反，系统通过“规则快照”机制在保证一致性的同时降低使用门槛。

### 4.1 规则快照机制与进入流程

系统在用户进入以下任一 Tab/流程时创建规则快照，用于锁定本次会话的规则上下文：

* 策略记忆
* 场景理解
* 无提示练习
* 连续实战模拟

创建快照的时机为“进入该 Tab 的首次渲染/开始按钮点击”之一（以实现体验最顺畅为准），并遵循以下原则：

* 快照创建后，在本次会话内规则不可被隐式改变
* 若用户希望调整规则，必须显式跳转到规则设置完成修改
* 完成修改后，系统应自动跳转回原 Tab，并保持用户原先的页面状态（例如：停留在同一张策略表、同一练习模式、同一练习进度或模拟准备页），并基于新规则创建新的快照继续

为了减少用户困惑与误用，系统在进入需要快照的 Tab 时应给出轻量确认：

* 显示当前将要使用的规则摘要
* 提供“继续”和“修改规则”两种选择
* 若选择“修改规则”，跳转到规则设置；保存后返回并恢复原状态

该机制的目标是：既能保证单次训练会话中的规则一致性，又不让用户在体验上被“规则管理”打断。

### 4.2 规则项定义与组织方式

规则项应覆盖基础训练与模拟所需的常见配置，并以用户可理解的方式组织在规则设置界面中。规则设置界面建议分为两组（可以用分区标题或 Tab 实现）：

* Table Rules：影响牌局与可用操作的规则（用于策略与判定）
* Game / Training Settings：不改变最优策略、只影响训练内容或展示的设置（用于训练体验）

其中，Table Rules 至少包含：

* 牌副数（Deck Count）
* Dealer 是否 Hit Soft 17（H17 / S17）
* Dealer 是否 Peek（Peek / No Peek）
* Double 的可用范围（Any / 10,11 / 9,10,11）
* Double After Split（允许 / 不允许）
* Surrender 类型（None / Early / Late）
* Blackjack 支付比例（如 3:2 / 6:5）
* Re-split 相关限制（是否允许、次数上限、Aces 是否可再分、Split Aces 是否可 Hit 等）

Game / Training Settings 仅用于控制训练体验与内容分布，不影响最优策略定义，常见包括：

* 训练模式筛选（只练 Hard / Soft / Pairs 等）
* 避免 Blackjack 场景
* Pair 练习中排除 10,10
* 是否显示手牌点数
* 是否显示已完成练习数量等辅助信息

连续实战模拟所需的资金与下注参数不作为全局规则常驻项，而是在“进入模拟前的参数确认”中单独输入（如初始钱包、止损止盈、快捷下注等），并在模拟开始时随规则快照一起冻结。

### 4.3 规则与统计系统的关系

统计聚合系统不需要区分不同规则配置下的结果，所有符合计入条件的训练数据应统一合并存储与展示，以降低存储复杂度与产品认知负担。

因此，统计系统遵循以下约束：

* 统计只反映“无提示环境下的真实决策表现”，而不按规则集拆分
* 规则变化不会导致统计被分桶或清空；统计持续累积
* 规则快照的作用是保证单次训练会话内部一致性，而非用于统计切片

同时，为保证统计可信度，系统仍需满足：

* 场景学习不计入统计
* 无提示练习计入统计
* 连续实战模拟在未使用任何提示的情况下计入统计；一旦使用提示，则本局模拟不计入统计，并在模拟内明确提示原因

上述设计在“保证训练会话一致性”和“保持统计系统简单可用”之间取得平衡，避免因规则拆分导致数据存储、展示与用户理解成本显著上升。

---

## 5. 策略记忆系统（三张策略表）

策略记忆系统由三张策略表构成：

* Hard Totals
* Soft Totals
* Pairs

每张表以 **玩家条件 × Dealer 明牌** 的二维结构展示，在当前规则下对应唯一最优动作。

策略表的职责是：

* 明确告诉用户“在这个条件下应该做什么”
* 作为后续所有学习与评估的权威参考

### 策略表的交互扩展（关键细节）

策略表不仅是静态展示，而是**主动学习入口**。

当用户点击任意一个策略表格子时，系统必须：

* 解析该格子所代表的完整决策条件
* 将该条件作为参数传递给场景学习系统
* 进入“定向场景学习模式”

此跳转必须保证：

* 展示的最优策略与表格完全一致
* 展示的统计解释可以反向对应到该格子的决策含义
* 用户清楚知道自己正在学习“哪一个策略格子”

---

## 6. 场景学习系统（Guided Scenario Learning）

场景学习系统用于**解释策略成立的原因**，而不是测试用户是否记住。

### 场景来源

场景学习有两种来源：

* 自由模式：系统随机生成任意决策场景
* 定向模式：由策略表点击进入，生成指定条件的场景

### 场景内容展示（细节要求）

在场景学习中，系统必须明确展示：

* 当前玩家手牌与 Dealer 明牌
* 所有合法可选动作
* 每个动作对应的统计指标（如 EV、胜率、Bust 概率等）
* 当前规则下的最优动作
* 对最优动作的文字解释

解释的目标不是数学严谨证明，而是**帮助用户建立直觉**，例如：

* 为什么在庄家弱牌下扩大下注是合理的
* 为什么某些负 EV 决策仍然是“正确决策”

### 数据约束

* 场景学习行为**不写入任何练习统计**
* 不影响用户的正确率、热力图或历史记录
* 用于理解，不用于评估

---

## 7. 练习系统（Unguided Practice · 单决策）

练习系统用于在**完全无提示环境下**检验用户的真实决策能力。

### 核心行为

在练习系统中：

* 系统随机生成决策场景
* 不显示任何统计信息、EV 或策略提示
* 用户只能基于记忆与理解选择动作

### 单次练习流程

一次完整练习包含以下阶段：

* 场景生成（规则冻结）
* 用户决策
* 系统判定决策是否最优
* 向用户展示反馈结果
* 展示与场景学习一致的策略解释
* 写入统计数据
* 自动进入下一手

### 统计写入原则

* 每一次练习都会更新三张统计表中对应的格子
* 同时记录时间维度上的练习次数
* 不允许用户在练习前查看统计提示

---

## 8. 练习系统变种：模拟牌桌模式（Table Simulation Practice）

模拟牌桌模式是练习系统的高阶形态，用于模拟连续操作、资金变化与心理压力。

### 进入模拟前的参数确认

在进入模拟前，系统要求用户明确确认：

* 本局使用的规则（可继承当前全局规则）
* 初始钱包金额
* 止损点
* 止盈点

系统必须同时提供：

* 常用参数组合的快速选项
* 明确说明这些参数在模拟过程中不可修改

### 模拟过程行为细节

在模拟过程中：

* 每次 Deal 前，用户选择下注金额
* 在资金允许的情况下，支持：

  * 快捷 Double
  * 快捷 Repeat 上一手下注
* 系统结算每一手的输赢并更新钱包余额
* 不显示任何策略或统计提示

模拟体验应尽量贴近真实牌桌操作节奏，而非“训练题目”。

---

### 场外提示开关（强约束细节）

模拟牌桌中允许存在一个“场外提示”功能开关，用于学习或安全目的。

该功能的约束非常严格：

* 一旦在本次模拟中任何时刻启用过提示
* 本次模拟将**永久失去计入历史统计的资格**
* 系统必须在界面中持续提示：
  “This simulation used external hints and will not be included in your training statistics.”

这是为了保证统计数据只反映**真实无辅助决策能力**。

---

### 模拟结束条件与总结

模拟在以下任一条件达成时结束：

* 钱包余额 ≤ 止损点
* 钱包余额 ≥ 止盈点
* 用户主动结束

模拟结束后，系统必须提供快速总结，包括：

* 起始资金与结束资金
* 总手数
* 是否计入历史统计及原因说明

---

## 9. 统计聚合系统（Statistics & Aggregation）

统计系统用于帮助用户**客观照见自己的决策能力**。

### 统计数据来源

只有以下行为会写入统计：

* 单决策练习
* 模拟牌桌练习（全程未使用提示）

场景学习与使用过提示的模拟，永远不会影响统计。

---

### 决策维度统计（三张统计表）

统计表结构与策略表完全一致：

* Hard / Soft / Pairs
* 每个格子聚合：

  * 累计练习次数
  * 决策正确率

该视图用于帮助用户发现：

* 哪些具体场景长期错误率高
* 哪些策略尚未内化

系统必须提供“一键重置统计”能力。

---

### 时间维度统计（短期热力图）

系统提供一个短期练习频率视图，形式类似 GitHub 的贡献热力图。

* 时间范围限定为最近 7 天
* 每天划分为固定时间段（22–2、2–6、6–10、10–14、14–18、18–22）
* 使用颜色深浅反映练习次数

该统计仅用于反映短期训练节律，不承担长期行为分析责任。

---

## 10. 一致性与可信原则（强约束）

系统必须始终遵守以下原则：

* 策略表、场景学习、练习、模拟共享同一策略定义
* 所有判定必须基于规则快照
* 任何计入统计的数据必须来自无提示环境
* 提示一旦使用，本次行为永久失去统计资格
* 重置统计不影响规则与策略

---

## 11. MVP 完成定义

当系统满足以下条件时，视为 MVP 完成：

* 规则系统完整可用
* 三张策略表完整且可跳转至场景学习
* 场景学习提供统计与解释
* 单决策练习完整可用并写入统计
* 模拟牌桌练习完整可用并正确区分统计资格
* 决策统计表与时间热力图正确更新
* 所有数据仅依赖 localStorage

---

## 12. 下一步：

1. 把这份 PRD **逐段映射到模块 / state / 数据结构**
2. 检查：**这套 PRD 是否在 MVP 阶段过重，哪里可以安全延后**
